{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "credit_card_data = pd.read_csv('/Volumes/LACIE_SHARE/python_scripts/Data/credit_card.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype\n",
      "---  ------                      --------------  -----\n",
      " 0   ID                          30000 non-null  int64\n",
      " 1   LIMIT_BAL                   30000 non-null  int64\n",
      " 2   SEX                         30000 non-null  int64\n",
      " 3   EDUCATION                   30000 non-null  int64\n",
      " 4   MARRIAGE                    30000 non-null  int64\n",
      " 5   AGE                         30000 non-null  int64\n",
      " 6   PAY_0                       30000 non-null  int64\n",
      " 7   PAY_2                       30000 non-null  int64\n",
      " 8   PAY_3                       30000 non-null  int64\n",
      " 9   PAY_4                       30000 non-null  int64\n",
      " 10  PAY_5                       30000 non-null  int64\n",
      " 11  PAY_6                       30000 non-null  int64\n",
      " 12  BILL_AMT1                   30000 non-null  int64\n",
      " 13  BILL_AMT2                   30000 non-null  int64\n",
      " 14  BILL_AMT3                   30000 non-null  int64\n",
      " 15  BILL_AMT4                   30000 non-null  int64\n",
      " 16  BILL_AMT5                   30000 non-null  int64\n",
      " 17  BILL_AMT6                   30000 non-null  int64\n",
      " 18  PAY_AMT1                    30000 non-null  int64\n",
      " 19  PAY_AMT2                    30000 non-null  int64\n",
      " 20  PAY_AMT3                    30000 non-null  int64\n",
      " 21  PAY_AMT4                    30000 non-null  int64\n",
      " 22  PAY_AMT5                    30000 non-null  int64\n",
      " 23  PAY_AMT6                    30000 non-null  int64\n",
      " 24  default payment next month  30000 non-null  int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "credit_card_data = pd.read_csv('/Volumes/LACIE_SHARE/python_scripts/Data/credit_card.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6636\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'marriage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Volumes/LACIE_SHARE/Software/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'marriage'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-2771e4804a6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m### sex, education, and marriage are numeric. Are they binary?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredit_card_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'marriage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredit_card_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'education'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/LACIE_SHARE/Software/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/LACIE_SHARE/Software/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'marriage'"
     ]
    }
   ],
   "source": [
    "print(np.max(credit_card_data['default payment next month']))\n",
    "print(np.sum(credit_card_data['default payment next month']))\n",
    "\n",
    "features = credit_card_data.drop('default payment next month', axis = 1)\n",
    "target = credit_card_data['default payment next month']\n",
    "\n",
    "\n",
    "### sex, education, and marriage are numeric. Are they binary?\n",
    "print(np.max(credit_card_data['marriage']))\n",
    "\n",
    "print(np.max(credit_card_data['education']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the sklearn modules\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(features, target, random_state = 0, test_size = 0.4)\n",
    "## Our dataset has 30000 observations, so we can get away with a larger test set.\n",
    "\n",
    "## We'll do scaling after the train/test split to avoid data leakage\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.fit_transform(X_test_org)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Training Accuracy: 1.0, Testing Accuracy: 0.7237\n",
      "k: 2, Training Accuracy: 0.8596, Testing Accuracy: 0.786\n",
      "k: 3, Training Accuracy: 0.8618, Testing Accuracy: 0.7768\n",
      "k: 4, Training Accuracy: 0.8361, Testing Accuracy: 0.7946\n",
      "k: 5, Training Accuracy: 0.8372, Testing Accuracy: 0.7931\n",
      "k: 6, Training Accuracy: 0.8271, Testing Accuracy: 0.8009\n",
      "k: 7, Training Accuracy: 0.8268, Testing Accuracy: 0.8026\n",
      "k: 8, Training Accuracy: 0.8224, Testing Accuracy: 0.8051\n",
      "k: 9, Training Accuracy: 0.8228, Testing Accuracy: 0.8053\n",
      "k: 10, Training Accuracy: 0.8197, Testing Accuracy: 0.8061\n",
      "k: 11, Training Accuracy: 0.8206, Testing Accuracy: 0.8077\n",
      "k: 12, Training Accuracy: 0.817, Testing Accuracy: 0.8078\n",
      "k: 13, Training Accuracy: 0.8177, Testing Accuracy: 0.8082\n",
      "k: 14, Training Accuracy: 0.8151, Testing Accuracy: 0.8082\n",
      "k: 15, Training Accuracy: 0.8157, Testing Accuracy: 0.8092\n",
      "k: 16, Training Accuracy: 0.8143, Testing Accuracy: 0.8093\n",
      "k: 17, Training Accuracy: 0.8144, Testing Accuracy: 0.809\n",
      "k: 18, Training Accuracy: 0.8125, Testing Accuracy: 0.8094\n",
      "k: 19, Training Accuracy: 0.8136, Testing Accuracy: 0.8088\n",
      "k: 20, Training Accuracy: 0.8109, Testing Accuracy: 0.8098\n",
      "k: 21, Training Accuracy: 0.8126, Testing Accuracy: 0.809\n",
      "k: 22, Training Accuracy: 0.8103, Testing Accuracy: 0.8097\n",
      "k: 23, Training Accuracy: 0.812, Testing Accuracy: 0.8089\n",
      "k: 24, Training Accuracy: 0.8104, Testing Accuracy: 0.8088\n",
      "k: 25, Training Accuracy: 0.8121, Testing Accuracy: 0.8102\n",
      "k: 26, Training Accuracy: 0.8094, Testing Accuracy: 0.8089\n",
      "k: 27, Training Accuracy: 0.8109, Testing Accuracy: 0.8092\n",
      "k: 28, Training Accuracy: 0.81, Testing Accuracy: 0.8084\n",
      "k: 29, Training Accuracy: 0.8106, Testing Accuracy: 0.8088\n"
     ]
    }
   ],
   "source": [
    "## K nearest neighbors\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "num_knn = 30\n",
    "\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "for k in range (1, num_knn):\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score_array.append(knn.score(X_train, y_train))\n",
    "    test_score_array.append(knn.score(X_test, y_test))\n",
    "    print(\"k = {}, Training Accuracy: {}, Testing Accuracy: {}\".\\\n",
    "          format(k, np.round(knn.score(X_train, y_train), decimals = 4),\\\n",
    "                 np.round(knn.score(X_test, y_test), decimals = 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our minimum distance occurred at k = 26\n",
      "our min distance was 0.0005277777777777937\n"
     ]
    }
   ],
   "source": [
    "## The optimal k value happens when our train and test value have their minimum distance. \n",
    "\n",
    "difference_array = []\n",
    "\n",
    "for i in range(0, num_knn-1):\n",
    "    difference_array.append(np.abs(train_score_array[i] - test_score_array[i]))\n",
    "\n",
    "print('our minimum distance occurred at k = {}'.\\\n",
    "      format(difference_array.index(np.amin(difference_array)) + 1)) \n",
    "#adding one because our knn testing started at 1, so the first value will be \n",
    "    \n",
    "print('our min distance was {}'.format(np.amin(difference_array)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 40 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 48.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=15, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'metric': ['euclidean', 'manhattan'],\n",
       "                         'n_neighbors': range(21, 40, 2),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Grid search algorithm using https://medium.com/@erikgreenj/k-neighbors-classifier-with-gridsearchcv-basics-3c445ddeb657\n",
    "## This search adjusts weights and method as well as k\n",
    "## (Dr Snell's program did not adjust anything but k so his grid search was redundant, I think)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k_vals = range(21, 40, 2) ## go by odd numbers because even k numbers can have ties. \n",
    "\n",
    "param_grid = {'n_neighbors': k_vals,\n",
    "             'weights': ['uniform', 'distance'], ## Can comment out weights and metric if it takes too long\n",
    "             'metric': ['euclidean', 'manhattan']\n",
    "             }\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), \n",
    "                           param_grid, \n",
    "                           verbose = 1,\n",
    "                           cv = 15, \n",
    "                           n_jobs = -1, ## use all my cores\n",
    "                           return_train_score = True)\n",
    "\n",
    "grid_search.fit(X_train, y_train) ## Our first model is made\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8072\n",
      "Best parameters: {'metric': 'euclidean', 'n_neighbors': 35, 'weights': 'distance'}\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "#Best score and parameters\n",
    "print(\"Best score: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "## Accuracy\n",
    "knn = KNeighborsClassifier(metric = 'euclidean', n_neighbors = 35, weights = 'distance')\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"Training Accuracy:\",knn.score(X_train, y_train)) #Accuracy of the model when training.\n",
    "print(\"Testing Accuracy:\", knn.score(X_test, y_test) )#Accuracy of the test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Precomputed matrix must be a square matrix. Input is a 18000x24 matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-7b78aa5f1653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprecomputed_svclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprecomputed_svclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/LACIE_SHARE/Software/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"precomputed\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             raise ValueError(\"Precomputed matrix must be a square matrix.\"\n\u001b[0m\u001b[1;32m    180\u001b[0m                              \u001b[0;34m\" Input is a {}x{} matrix.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                              .format(X.shape[0], X.shape[1]))\n",
      "\u001b[0;31mValueError\u001b[0m: Precomputed matrix must be a square matrix. Input is a 18000x24 matrix."
     ]
    }
   ],
   "source": [
    "## Support Vector Classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.svm import SVC  \n",
    "\n",
    "linear_svclassifier = SVC(kernel='linear')  \n",
    "linear_svclassifier.fit(X_train, y_train) \n",
    "\n",
    "poly_svclassifier = SVC(kernel='poly')  \n",
    "poly_svclassifier.fit(X_train, y_train) \n",
    "\n",
    "rbf_svclassifier = SVC(kernel='rbf')  \n",
    "rbf_svclassifier.fit(X_train, y_train) \n",
    "\n",
    "sigmoid_svclassifier = SVC(kernel='sigmoid')  \n",
    "sigmoid_svclassifier.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### We now have 4 SVCs to choose from \n",
    "\n",
    "## We can do a grid search for each one\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005277777777777937\n",
      "0.0019444444444444153\n"
     ]
    }
   ],
   "source": [
    "## We want the results of our individual models to be poorly correlated but also better than a naive. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" At a minimum you should report F1 scores, ROC curve, and AUC, \n",
    " but you might also want to consider using  accuracy scores, \n",
    " confusion matrices, recall, precision, sensitivity, specificity, \n",
    "false positives, false negatives, Matthews correlation coefficient etc \"\"\"\n",
    "\n",
    "ROC = \n",
    "F1 = \n",
    "AUC = \n",
    "accuracy = \n",
    "conf_matrix = \n",
    "recall = \n",
    "precision = \n",
    "sensitivity = \n",
    "specificty = \n",
    "f_pos = \n",
    "f_neg = \n",
    "matt_cor = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
